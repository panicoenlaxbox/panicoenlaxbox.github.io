<!doctype html><html lang=es itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Trino en Azure - Programación desordenada</title><meta name=description content="La idea de este post es colocar en el mapa a Trino e instalarlo sobre un clúster de VMs en Azure. En realidad, es lo que me hubiera gustado encontrar hace unas semanas para ahorrarnos (a mí y a Alejandro García Miravet) un montón de prueba y error. Si alguien quiere probar Trino, espero que lo tenga un poco más fácil después de leer este post."><meta name=author content="Sergio León"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"Programación desordenada","url":"https:\/\/panicoenlaxbox.com"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"https:\/\/panicoenlaxbox.com"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https:\/\/panicoenlaxbox.com","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"https:\/\/panicoenlaxbox.com\/post\/trino-en-azure\/","name":"Trino en azure"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"Sergio León"},"headline":"Trino en Azure","description":"La idea de este post es colocar en el mapa a Trino e instalarlo sobre un clúster de VMs en Azure. En realidad, es lo que me hubiera gustado encontrar hace unas semanas para ahorrarnos (a mí y a Alejandro García Miravet) un montón de prueba y error. Si alguien quiere probar Trino, espero que lo tenga un poco más fácil después de leer este post.\n","inLanguage":"es","wordCount":2569,"datePublished":"2021-10-11T10:12:54","dateModified":"2021-10-11T10:12:54","image":"https:\/\/panicoenlaxbox.com\/img\/avatar-icon.png","keywords":["azure, trino"],"mainEntityOfPage":"https:\/\/panicoenlaxbox.com\/post\/trino-en-azure\/","publisher":{"@type":"Organization","name":"https:\/\/panicoenlaxbox.com","logo":{"@type":"ImageObject","url":"https:\/\/panicoenlaxbox.com\/img\/avatar-icon.png","height":60,"width":60}}}</script><meta property="og:title" content="Trino en Azure"><meta property="og:description" content="La idea de este post es colocar en el mapa a Trino e instalarlo sobre un clúster de VMs en Azure. En realidad, es lo que me hubiera gustado encontrar hace unas semanas para ahorrarnos (a mí y a Alejandro García Miravet) un montón de prueba y error. Si alguien quiere probar Trino, espero que lo tenga un poco más fácil después de leer este post."><meta property="og:image" content="https://panicoenlaxbox.com/img/avatar-icon.png"><meta property="og:url" content="https://panicoenlaxbox.com/post/trino-en-azure/"><meta property="og:type" content="website"><meta property="og:site_name" content="Programación desordenada"><meta name=twitter:title content="Trino en Azure"><meta name=twitter:description content="La idea de este post es colocar en el mapa a Trino e instalarlo sobre un clúster de VMs en Azure. En realidad, es lo que me hubiera gustado encontrar hace unas semanas para ahorrarnos (a mí y a …"><meta name=twitter:image content="https://panicoenlaxbox.com/img/avatar-icon.png"><meta name=twitter:card content="summary"><meta name=twitter:site content="@panicoenlaxbox"><meta name=twitter:creator content="@panicoenlaxbox"><link href=https://panicoenlaxbox.com/img/favicon.ico rel=icon type=image/x-icon><meta name=generator content="Hugo 0.107.0"><link rel=alternate href=https://panicoenlaxbox.com/index.xml type=application/rss+xml title="Programación desordenada"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css integrity=sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.5.0/css/all.css integrity=sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://panicoenlaxbox.com/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"><link rel=stylesheet href=https://panicoenlaxbox.com/css/highlight.min.css><link rel=stylesheet href=https://panicoenlaxbox.com/css/codeblock.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css integrity=sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css integrity=sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R crossorigin=anonymous><style>.intro-header .archive-heading{text-align:center}.intro-header .archive-heading h1{margin-top:0;font-size:50px}@media only screen and (min-width:768px){.intro-header .archive-heading h1{font-size:80px}}.post-entry a{color:#008aff}body.dark-mode,body.dark-mode main *{background:#2d2d2d;color:#f5f5f5}body.dark-mode .post-title,body.dark-mode .post-subtitle{color:#f5f5f5}body.dark-mode .post-entry a{color:#008aff}body.dark-mode table tr th,body.dark-mode table tr td{color:#333}blockquote{margin:20px}table{margin-top:10px}</style><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-57023975-1","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class=container-fluid><div class=navbar-header><button type=button class=navbar-toggle data-toggle=collapse data-target=#main-navbar>
<span class=sr-only>Conmuta navegación</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=https://panicoenlaxbox.com>Programación desordenada</a></div><div class="collapse navbar-collapse" id=main-navbar><ul class="nav navbar-nav navbar-right"><li><a title=Tags href=/tags>Tags</a></li><li><a title=Archive href=/archive>Archive</a></li><li><a title=About href=/about>About</a></li></ul></div><div class=avatar-container><div class=avatar-img-border><a title="Programación desordenada" href=https://panicoenlaxbox.com><img class=avatar-img src=https://panicoenlaxbox.com/img/avatar-icon.png alt="Programación desordenada"></a></div></div></div></nav><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><h1>Trino en Azure</h1><span class=post-meta><i class="fas fa-calendar"></i>&nbsp;Publicado el October 11, 2021</span></div></div></div></div></div></header><div class=js-toggle-wrapper><div class=js-toggle><div class=js-toggle-track><div class=js-toggle-track-check><img src="data:image/png;base64,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" role=presentation style=pointer-events:none width=16 height=16></div><div class=js-toggle-track-x><img src="data:image/png;base64,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" role=presentation style=pointer-events:none width=16 height=16></div></div><div class=js-toggle-thumb></div><input class=js-toggle-screenreader-only type=checkbox aria-label="Switch between Dark and Light mode"></div></div><style>.js-toggle-wrapper{display:table;margin:0 auto}.js-toggle{touch-action:pan-x;display:inline-block;position:relative;cursor:pointer;background-color:transparent;border:0;padding:0;-webkit-touch-callout:none;user-select:none;-webkit-tap-highlight-color:transparent;-webkit-tap-highlight-color:transparent}.js-toggle-screenreader-only{border:0;clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}.js-toggle-track{width:50px;height:24px;padding:0;border-radius:30px;background-color:#0f1114;transition:all .2s ease}.js-toggle-track-check{position:absolute;width:17px;height:17px;left:5px;top:0;bottom:0;margin-top:auto;margin-bottom:auto;line-height:0;opacity:0;transition:opacity .25s ease}.js-toggle--checked .js-toggle-track-check{opacity:1;transition:opacity .25s ease}.js-toggle-track-x{position:absolute;width:17px;height:17px;right:5px;top:0;bottom:0;margin-top:auto;margin-bottom:auto;line-height:0;opacity:1;transition:opacity .25s ease}.js-toggle--checked .js-toggle-track-x{opacity:0}.js-toggle-thumb{position:absolute;top:1px;left:1px;width:22px;height:22px;border-radius:50%;background-color:#fafafa;box-sizing:border-box;transition:all .5s cubic-bezier(.23,1,.32,1)0ms;transform:translateX(0)}.js-toggle--checked .js-toggle-thumb{transform:translateX(26px);border-color:#19ab27}.js-toggle--focus .js-toggle-thumb{box-shadow:0 0 2px 3px #ffa7c4}.js-toggle:active .js-toggle-thumb{box-shadow:0 0 5px 5px #ffa7c4}</style><script>var body=document.body,switcher=document.getElementsByClassName("js-toggle")[0];switcher.addEventListener("click",function(){this.classList.toggle("js-toggle--checked"),this.classList.add("js-toggle--focus"),this.classList.contains("js-toggle--checked")?(body.classList.add("dark-mode"),localStorage.setItem("darkMode","true")):(body.classList.remove("dark-mode"),setTimeout(function(){localStorage.removeItem("darkMode")},100))}),localStorage.getItem("darkMode")&&(switcher.classList.add("js-toggle--checked"),body.classList.add("dark-mode"))</script><div class=container role=main><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><article role=main class=blog-post><p>La idea de este post es colocar en el mapa a <a href=https://Trino.io/>Trino</a> e instalarlo sobre un clúster de VMs en Azure. En realidad, es lo que me hubiera gustado encontrar hace unas semanas para ahorrarnos (a mí y a <a href=https://twitter.com/alexmiravet>Alejandro García Miravet</a>) un montón de prueba y error. Si alguien quiere probar Trino, espero que lo tenga un poco más fácil después de leer este post.</p><blockquote><p>Trino is a distributed SQL query engine designed to query large data sets distributed over one or more heterogeneous data sources.</p><p><a href=https://trino.io/docs/current/overview.html>https://trino.io/docs/current/overview.html</a></p></blockquote><p>Lo que me llamó la atención es: primero, usar un mismo lenguaje para acceder a distintos orígenes de datos; segundo, usar un clúster para poder escalar en horizontal.</p><p>Además Trino permite ejecutar <em>federated queries</em>, esto es poder hacer <code>join</code> entre 2 tablas de 2 orígenes de datos distintos. Al final, podemos ver a Trino como un <em>&ldquo;data warehouse virtual&rdquo;</em>, donde sin necesidad de un ETL, tenemos una vista unificada de todos los datos de nuestra compañía.</p><p>Como curiosidad, a Trino también se le conoce como prestoSQL y hay una <a href=https://trino.io/blog/2020/12/27/announcing-trino.html>historia muy interesante</a> detrás de la &ldquo;rivalidad&rdquo; entre <a href=https://prestodb.io/>prestodb</a> y Trino.</p><p>En nuestro caso particular estamos evaluando Trino como alternativa a <a href=https://spark.apache.org/>Spark</a> y a <a href=https://hive.apache.org/>Hive</a> sobre ficheros <em>.csv</em> y <em>.parquet</em> en una cuenta de almacenamiento de tipo ADLS Gen2, y lo de <a href=https://www.bluegranite.com/blog/10-things-to-know-about-azure-data-lake-storage-gen2>Gen2 es importante</a>.</p><p>Trino también está disponible como un <a href=https://azuremarketplace.microsoft.com/en-us/marketplace/apps/starburstdatainc1582306810515.starburst-enterprise-presto>servicio administrado</a> en Azure a través de la empresa <a href=https://www.starburst.io/platform/deployment-options/starburst-on-azure/>Startbust</a>.</p><p>La arquitectura de Trino a alto nivel es bastante sencilla. Un clúster está formado por un <a href=https://trino.io/docs/current/overview/concepts.html#coordinator>coordinator</a> y <em>n</em> <a href=https://trino.io/docs/current/overview/concepts.html#worker>workers</a>. Un <a href=https://trino.io/docs/current/client.html>cliente</a> conectará al coordinator para ejecutar una consulta SQL (a través de JDBC, ODBC, REST API o cualquiera de las librerías disponibles: Python, Go, Node, Ruby, etc). Después un <a href=https://trino.io/docs/current/connector.html>conector</a> leerá datos del origen (haciéndolo mejor o peor, en paralelo o no, todo ello según la implementación del propio conector) y finalmente, se procesará la consulta de forma distribuida en la memoria de los workers.</p><p>Personalmente, algo que me hizo mucho daño al comienzo fue pensar que Hive era necesario siempre en el coordinator. Sin embargo, sólo es necesario si vas a usar el conector de Hive para acceder a un object storage (por ejemplo ADLS o S3). <a href=https://trino.io/blog/2020/10/20/intro-to-hive-connector.html>En este post lo explican bastante bien</a> y parece es una confusión bastante habitual.</p><p>El único problema que veo a Trino por ahora es que no hay un driver ODBC OOS (sí que hay JDBC). Startbust lo ofrece como parte de su servicio administrado y otras empresas como <a href=https://www.magnitude.com/drivers/presto-odbc-jdbc>Magnitude</a> también lo comercializan&mldr; pero no es barato, pregunté y me quedé muerto.</p><p>Si comparamos <a href=https://spark.apache.org/>Spark</a> con Trino, lo que estamos comparando es un framework, que hace muchas cosas y bien, contra un programa que sólo hace una cosa pero, en teoría, la hace mejor (<em>right tool for the right job</em>). Mis primeras impresiones (sin ningún rigor técnico) son que, efectivamente, la misma consulta se ejecuta más rápido en Trino. Por el contrario, si usas Spark en Databricks, no tendrás ningún problema con el <a href=https://databricks.com/spark/odbc-drivers-download>driver ODBC</a> y además la gestión del clúster y todo el ecosistema que le rodea es muy sencilla. Incluso el correcto dimensionamiento del clúster parece menos importante en Databricks porque <a href=https://databricks.com/blog/2017/12/01/transparent-autoscaling-of-instance-storage.html>Spark</a> terminará usando mucho más el spill que <a href=https://trino.io/docs/current/admin/spill.html#supported-operations>Trino</a> (<em>spill es como un swap, volcar datos intermedios desde memoria a disco y vicerversa</em>), y como se <a href=https://docs.microsoft.com/en-us/azure/databricks/clusters/configure#---autoscaling-local-storage>añadirán discos de forma automática al clúster</a>, termina siendo muy cómodo no tener que hacer un ajuste tan fino de antemano como <a href=https://shopify.engineering/faster-trino-query-execution-infrastructure>sí nos obligará a hacer Trino</a>. También es cierto que hacer spill no es algo bueno, en un mundo ideal no debería pasar, la memoria es rápida, el IO a disco ya no tanto. En cualquier caso, no conviene olvidar que todo la magia de Databricks irá acompañada después de unos bonitos <a href=https://azure.microsoft.com/en-us/pricing/details/databricks/>DBUs en la factura</a>.</p><p>Para probar Trino en local, lo más sencillo es usar Docker con los <a href=https://trino.io/docs/current/overview/concepts.html#catalog>catálogos</a> <a href=https://trino.io/docs/current/connector/tpch.html#>tpch</a> y <a href=https://trino.io/docs/current/connector/tpcds.html>tpcds</a> que, en el caso de Trino, generan datos al vuelvo para simular una carga de tipo <a href=http://www.tpc.org/tpch/>OLTP</a> y <a href=http://www.tpc.org/tpcds/>OLAP</a>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>docker run -d --name trino-getting-started -p 8080:8080 trinodb/trino <span class=c1># download trino image, run in the background and expose 8080 port</span>
</span></span><span class=line><span class=cl>docker <span class=nb>exec</span> -it trino-getting-started trino <span class=c1># execute trino-client and attach interactive terminal</span>
</span></span><span class=line><span class=cl>trino&gt; SELECT * FROM tpch.sf1.customer<span class=p>;</span> -- SELECT * FROM catalog.schema.table<span class=p>;</span>
</span></span><span class=line><span class=cl>trino&gt; <span class=nb>exit</span> 
</span></span><span class=line><span class=cl>docker stop trino-getting-started <span class=c1># stop running container</span>
</span></span><span class=line><span class=cl>docker rm trino-getting-started <span class=c1># remove container</span>
</span></span><span class=line><span class=cl>docker rmi trinodb/trino <span class=c1># remove image</span>
</span></span></code></pre></div><p><img src=images/trino.png alt="trino UI en puerto 8080"></p><p>Parece claro que un clúster de 1 nodo no va a ser suficiente si queremos ver funcionar a Trino en todo su esplendor así que, dejando a un lado Docker, yo he optado por crear VMs en Azure porque además quería trastear un poco con Linux.</p><p>Con el fichero <code>cluster.sh</code> crearemos en Azure todo lo necesario para el clúster:</p><ul><li><code>YOUR_SUBSCRIPION_ID</code></li><li><code>YOUR_PASSWORD</code></li><li><code>YOUR_PUBLIC_IP</code><ul><li>Si tienes 2 o más IPs públicas sepáralas por espacios.</li></ul></li></ul><p><em>Es verdad que es mejor usar una clave privada que una contraseña para conectar por</em> <code>ssh</code><em>, pero en un entorno de dev/testing, una contraseña facilita mucha la vida.</em></p><p><code>cluster.sh</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span>az login
</span></span><span class=line><span class=cl><span class=nv>subscription</span><span class=o>=</span>YOUR_SUBSCRIPTION_ID
</span></span><span class=line><span class=cl>az account <span class=nb>set</span> --subscription <span class=nv>$subscription</span>
</span></span><span class=line><span class=cl>az group create --name rg-trino --location westeurope
</span></span><span class=line><span class=cl>az network nsg create --name nsg-trino --resource-group rg-trino
</span></span><span class=line><span class=cl>az network vnet create --name vnet-trino --resource-group rg-trino --network-security-group nsg-trino --subnet-name snet-trino
</span></span><span class=line><span class=cl>az network vnet subnet update --network-security-group nsg-trino --name snet-trino --resource-group rg-trino --vnet-name vnet-trino
</span></span><span class=line><span class=cl>az network public-ip create --name pip-vm-coordinator --resource-group rg-trino --allocation-method Static --sku Basic
</span></span><span class=line><span class=cl><span class=nv>image</span><span class=o>=</span>canonical:0001-com-ubuntu-server-focal:20_04-lts:latest
</span></span><span class=line><span class=cl><span class=nv>size</span><span class=o>=</span>Standard_DS1_v2
</span></span><span class=line><span class=cl><span class=nv>password</span><span class=o>=</span>YOUR_PASSWORD
</span></span><span class=line><span class=cl><span class=nv>username</span><span class=o>=</span>azureuser
</span></span><span class=line><span class=cl><span class=nv>storage_sku</span><span class=o>=</span>Standard_LRS
</span></span><span class=line><span class=cl>az vm create --name vm-coordinator --resource-group rg-trino --image <span class=nv>$image</span> --size <span class=nv>$size</span> --admin-password <span class=nv>$password</span> --admin-username <span class=nv>$username</span> --authentication-type password --nsg <span class=s1>&#39;&#39;</span> --public-ip-address pip-vm-coordinator --subnet snet-trino --vnet-name vnet-trino --storage-sku <span class=nv>$storage_sku</span>
</span></span><span class=line><span class=cl><span class=k>for</span> i in <span class=o>{</span>1..2<span class=o>}</span> <span class=c1># choose your cluster size</span>
</span></span><span class=line><span class=cl><span class=k>do</span>
</span></span><span class=line><span class=cl>   az network public-ip create --name pip-vm-worker<span class=nv>$i</span> --resource-group rg-trino --allocation-method Static --sku Basic
</span></span><span class=line><span class=cl>   az vm create --name vm-worker<span class=nv>$i</span> --resource-group rg-trino --image <span class=nv>$image</span> --size <span class=nv>$size</span> --admin-password <span class=nv>$password</span> --admin-username <span class=nv>$username</span> --authentication-type password --nsg <span class=s1>&#39;&#39;</span> --public-ip-address pip-vm-worker<span class=nv>$i</span> --subnet snet-trino --vnet-name vnet-trino --storage-sku <span class=nv>$storage_sku</span>   
</span></span><span class=line><span class=cl><span class=k>done</span>
</span></span><span class=line><span class=cl><span class=nv>public_ip</span><span class=o>=</span>YOUR_PUBLIC_IP
</span></span><span class=line><span class=cl>az network nsg rule create --name nsgsr-ssh --nsg-name nsg-trino --priority <span class=m>300</span> --resource-group rg-trino --access Allow --direction Inbound --protocol Tcp --destination-port-ranges <span class=m>22</span> --source-address-prefixes <span class=nv>$public_ip</span>
</span></span><span class=line><span class=cl>az network nsg rule create --name nsgsr-sql --nsg-name nsg-trino --priority <span class=m>310</span> --resource-group rg-trino --access Allow --direction Inbound --protocol Tcp --destination-port-ranges <span class=m>1433</span> --source-address-prefixes <span class=nv>$public_ip</span>
</span></span><span class=line><span class=cl>az network nsg rule create --name nsgsr-http --nsg-name nsg-trino --priority <span class=m>320</span> --resource-group rg-trino --access Allow --direction Inbound --protocol Tcp --destination-port-ranges <span class=m>8080</span> --source-address-prefixes <span class=nv>$public_ip</span>
</span></span></code></pre></div><p>Teniendo ya las VMs creadas, es hora de instalar los prerequisitos de Trino:</p><ul><li>Java.</li><li>Python.</li><li>Sólo en el coordinator (o en un <a href=https://app.slack.com/client/TFKPX15NC/CFLB9AMBN>nodo dedicado a ello en exclusiva</a>) y si vas a usar el conector de Hive:<ul><li><a href=https://cwiki.apache.org/confluence/display/Hive/AdminManual+Metastore+3.0+Administration>Hive metastore standalone</a>.</li><li>Un RDBMS.</li></ul></li></ul><p>Hive necesita un BD externa porque de serie guarda los metadatos en memoria usando <a href=https://db.apache.org/derby/docs/10.8/devguide/cdevdvlpinmemdb.html>derby</a> que no es apta para producción.</p><p>En mi caso, he optado por SQL Server. Para instalarlo, lo más sencillo es seguir los pasos de la <a href="https://docs.microsoft.com/en-us/sql/linux/quickstart-install-connect-ubuntu?view=sql-server-ver15">documentación</a> oficial. En cualquier caso y para <em>Ubuntu 20.04</em>, con lo siguiente bastaría:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>wget -qO- https://packages.microsoft.com/keys/microsoft.asc <span class=p>|</span> sudo apt-key add -
</span></span><span class=line><span class=cl>sudo add-apt-repository <span class=s2>&#34;</span><span class=k>$(</span>wget -qO- https://packages.microsoft.com/config/ubuntu/20.04/mssql-server-2019.list<span class=k>)</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>sudo apt-get update
</span></span><span class=line><span class=cl>sudo apt-get install -y mssql-server
</span></span><span class=line><span class=cl>sudo /opt/mssql/bin/mssql-conf setup
</span></span><span class=line><span class=cl>sudo apt-get update 
</span></span><span class=line><span class=cl>sudo apt install curl
</span></span><span class=line><span class=cl>curl https://packages.microsoft.com/keys/microsoft.asc <span class=p>|</span> sudo apt-key add -
</span></span><span class=line><span class=cl>curl https://packages.microsoft.com/config/ubuntu/20.04/prod.list <span class=p>|</span> sudo tee /etc/apt/sources.list.d/msprod.list
</span></span><span class=line><span class=cl>sudo apt-get update 
</span></span><span class=line><span class=cl>sudo apt-get install -y mssql-tools unixodbc-dev
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;export PATH=&#34;$PATH:/opt/mssql-tools/bin&#34;&#39;</span> &gt;&gt; ~/.bashrc
</span></span><span class=line><span class=cl><span class=nb>source</span> ~/.bashrc
</span></span></code></pre></div><p>Para confirmar que SQL Server está funcionando correctamente, puedes ejecutar <code>sqlcmd -S localhost -U SA -P 'YOUR_PASSWORD'</code> y alguna consulta sencilla como <code>SELECT @@VERSION;</code>.</p><p>En cuanto al resto de prerrequisitos, con la ayuda de <code>sshpass</code>, <code>ssh</code> y <code>scp</code> intentaremos hacer la tarea un poco más llevadera.</p><p>El fichero que tienes que ejecutar en local es <code>install_prerequisites.sh</code> (que ejecutará en remoto <code>prerequisites.sh</code> y <code>coordinator_prerequisites.sh</code>), y habiendo reemplazado previamente <code>YOUR_PASSWORD</code>, <code>YOUR_PUBLIC_COORDINATOR_IP</code>, <code>YOUR_PUBLIC_WORKER_IP_1</code>, <code>YOUR_PUBLIC_WORKER_IP_2</code> y así sucesivamente.</p><p>Puedes recuperar las IPs públicas de todos los nodos del clúster con el siguiente comando, siendo la primera IP la de vm-coordinator (por la ordenación alfabética):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>az network public-ip list --query <span class=s2>&#34;sort_by([], &amp;name)[?resourceGroup == &#39;rg-trino&#39;].ipAddress&#34;</span>
</span></span></code></pre></div><p><code>install_prerequisites.sh</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=nv>password</span><span class=o>=</span>YOUR_PASSWORD
</span></span><span class=line><span class=cl><span class=nv>public_ip_list</span><span class=o>=(</span>YOUR_PUBLIC_COORDINATOR_IP YOUR_PUBLIC_WORKER_IP_1 YOUR_PUBLIC_WORKER_IP_2<span class=o>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> public_ip in <span class=s2>&#34;</span><span class=si>${</span><span class=nv>public_ip_list</span><span class=p>[@]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl><span class=k>do</span> 
</span></span><span class=line><span class=cl>   sshpass -p <span class=nv>$password</span> scp -r -o <span class=nv>StrictHostKeyChecking</span><span class=o>=</span>no prerequisites.sh azureuser@<span class=nv>$public_ip</span>:/home/azureuser/
</span></span><span class=line><span class=cl>   sshpass -p <span class=nv>$password</span> ssh -o <span class=nv>StrictHostKeyChecking</span><span class=o>=</span>no azureuser@<span class=nv>$public_ip</span> <span class=s1>&#39;chmod +x prerequisites.sh;./prerequisites.sh&#39;</span>
</span></span><span class=line><span class=cl><span class=k>done</span>
</span></span><span class=line><span class=cl><span class=nv>coordinator_public_ip</span><span class=o>=</span><span class=si>${</span><span class=nv>public_ip_list</span><span class=p>[0]</span><span class=si>}</span>
</span></span><span class=line><span class=cl>sshpass -p <span class=nv>$password</span> scp -r -o <span class=nv>StrictHostKeyChecking</span><span class=o>=</span>no coordinator_prerequisites.sh hive.sql azureuser@<span class=nv>$coordinator_public_ip</span>:/home/azureuser/
</span></span><span class=line><span class=cl>sshpass -p <span class=nv>$password</span> ssh -o <span class=nv>StrictHostKeyChecking</span><span class=o>=</span>no azureuser@<span class=nv>$coordinator_public_ip</span> <span class=s1>&#39;chmod +x coordinator_prerequisites.sh;./coordinator_prerequisites.sh&#39;</span>
</span></span></code></pre></div><p><code>prerequisites.sh</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span>wget -q https://cdn.azul.com/zulu/bin/zulu11.50.19-ca-jre11.0.12-linux_x64.tar.gz -O zulu11.50.19-ca-jre11.0.12-linux_x64.tar.gz
</span></span><span class=line><span class=cl>tar -xzvf zulu11.50.19-ca-jre11.0.12-linux_x64.tar.gz
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=nb>export</span> <span class=nv>JAVA_HOME</span><span class=o>=</span>~/zulu11.50.19-ca-jre11.0.12-linux_x64 &gt;&gt; .bashrc
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;export PATH=$PATH:$JAVA_HOME/bin&#39;</span> &gt;&gt; .bashrc
</span></span><span class=line><span class=cl>sudo apt install python-is-python3
</span></span></code></pre></div><p><code>coordinator_prerequisites.sh</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span>wget -q https://repo1.maven.org/maven2/org/apache/hive/hive-standalone-metastore/3.1.2/hive-standalone-metastore-3.1.2-bin.tar.gz -O hive-standalone-metastore-3.1.2-bin.tar.gz
</span></span><span class=line><span class=cl>tar -zxvf hive-standalone-metastore-3.1.2-bin.tar.gz
</span></span><span class=line><span class=cl>wget -q https://downloads.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz -O hadoop-3.3.1.tar.gz
</span></span><span class=line><span class=cl>tar -zxvf hadoop-3.3.1.tar.gz
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=nb>export</span> <span class=nv>HADOOP_HOME</span><span class=o>=</span>~/hadoop-3.3.1 &gt;&gt; .bashrc
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;export PATH=$PATH:$HADOOP_HOME/bin&#39;</span> &gt;&gt; .bashrc
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=nb>export</span> <span class=nv>HIVE_HOME</span><span class=o>=</span>~/apache-hive-metastore-3.1.2-bin &gt;&gt; .bashrc
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;export PATH=$PATH:$HIVE_HOME/bin&#39;</span> &gt;&gt; .bashrc
</span></span><span class=line><span class=cl>cp hadoop-3.3.1/share/hadoop/tools/lib/*azure*.jar hadoop-3.3.1/share/hadoop/common/lib/
</span></span><span class=line><span class=cl>cp hadoop-3.3.1/share/hadoop/tools/lib/wildfly-openssl-1.0.7.Final.jar hadoop-3.3.1/share/hadoop/common/lib/
</span></span><span class=line><span class=cl>/opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P YOUR_PASSWORD -i hive.sql
</span></span><span class=line><span class=cl>wget -q https://download.microsoft.com/download/b/c/5/bc5e407f-97ff-42ea-959d-12f2391063d7/sqljdbc_9.4.0.0_enu.tar.gz -O sqljdbc_9.4.0.0_enu.tar.gz
</span></span><span class=line><span class=cl>tar -xzvf sqljdbc_9.4.0.0_enu.tar.gz
</span></span><span class=line><span class=cl>cp sqljdbc_9.4/enu/mssql-jdbc-9.4.0.jre8.jar ~/apache-hive-metastore-3.1.2-bin/lib
</span></span></code></pre></div><p>Con <code>hive.sql</code> (y reemplazando previamente <code>YOUR_PASSWORD</code>) crearemos un base de datos vacía para usar después con Hive.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>CREATE</span><span class=w> </span><span class=k>DATABASE</span><span class=w> </span><span class=n>hive</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GO</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>CREATE</span><span class=w> </span><span class=n>LOGIN</span><span class=w> </span><span class=n>hive</span><span class=w> </span><span class=k>WITH</span><span class=w> </span><span class=n>PASSWORD</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;YOUR_PASSWORD&#39;</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GO</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>USE</span><span class=w> </span><span class=n>hive</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GO</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>CREATE</span><span class=w> </span><span class=k>USER</span><span class=w> </span><span class=n>hive</span><span class=w> </span><span class=k>FOR</span><span class=w> </span><span class=n>LOGIN</span><span class=w> </span><span class=n>hive</span><span class=p>;</span><span class=w> </span><span class=c1>-- public
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>GO</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>ALTER</span><span class=w> </span><span class=k>ROLE</span><span class=w> </span><span class=n>db_owner</span><span class=w> </span><span class=k>ADD</span><span class=w> </span><span class=n>MEMBER</span><span class=w> </span><span class=n>hive</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GO</span><span class=w>
</span></span></span></code></pre></div><p>Antes de pedir a Hive que cree todo lo necesario dentro de la base de datos recién creada, es necesario en el coordinator el fichero de configuración <code>/home/azureuser/apache-hive-metastore-3.1.2-bin/conf/metastore-site.xml</code>, siendo <code>YOUR_PASSWORD</code> el que especificamos en <code>hive.sql</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=cp>&lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34; standalone=&#34;no&#34;?&gt;</span>
</span></span><span class=line><span class=cl><span class=cp>&lt;?xml-stylesheet type=&#34;text/xsl&#34; href=&#34;configuration.xsl&#34;?&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>javax.jdo.option.ConnectionURL<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>jdbc:sqlserver://localhost:1433;DatabaseName=Hive;<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>javax.jdo.option.ConnectionDriverName<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>com.microsoft.sqlserver.jdbc.SQLServerDriver<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>javax.jdo.option.ConnectionUserName<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>hive<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>javax.jdo.option.ConnectionPassword<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>YOUR_PASSWORD<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>metastore.thrift.uris<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>thrift://localhost:9083<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;description&gt;</span>Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.<span class=nt>&lt;/description&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>metastore.task.threads.always<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>org.apache.hadoop.hive.metastore.events.EventCleanerTask<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>metastore.expression.proxy<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>org.apache.hadoop.hive.metastore.DefaultPartitionExpressionProxy<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/configuration&gt;</span>
</span></span></code></pre></div><p>Ahora podemos ejecutar el script de inicialización de Hive con <code>schematool</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>schematool -dbType mssql -initSchema
</span></span></code></pre></div><p>Para acceder con Hive a nuestra cuenta de almacenamiento en Azure tendremos que crear un <em>Service Principal</em> y darle permisos de <em>Storage Blob Data Owner</em>. Además hay que incluir lo siguiente en el fichero <code>metastore-site.xml</code>, prestando atención a <code>fs.azure.account.oauth2.client.endpoint</code> que tiene ser la versión 1 del endpoint de token (no vale la 2). La documentación de este fichero está <a href=https://hadoop.apache.org/docs/stable/hadoop-azure/abfs.html#OAuth_2.0_Client_Credentials>aquí</a>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>fs.azure.account.auth.type<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>OAuth<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>fs.azure.account.oauth.provider.type<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>fs.azure.account.oauth2.client.endpoint<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>YOUR_OAUTH_20_TOKEN_ENDPOINT_V1<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>fs.azure.account.oauth2.client.id<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>YOUR_CLIENT_ID<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;property&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;name&gt;</span>fs.azure.account.oauth2.client.secret<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;value&gt;</span>YOUR_SECRET<span class=nt>&lt;/value&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/property&gt;</span>
</span></span></code></pre></div><p>En este momento ya podemos arrancar Hive con <code>start-metastore &</code>. Con <code>jobs</code> verás algo así <code>[1]+ Running start-metastore &</code>. Si además queremos confirmar que está escuchando en el puerto indicado, podemos hacerlo con <code>sudo netstat -tulpn | grep LISTEN</code>. Para detener Hive, tanto <code>kill &lt;pid></code> como <code>kill %job_id</code> bastarán.</p><p>Con todo listo, llega el momento de instalar Trino en el clúster.</p><p>Además de la instalacion, Trino requiere de una <a href="https://trino.io/docs/current/installation/deployment.html?highlight=config%20properties#configuring-trino">configuración</a> tanto en el coordinator como en los workers). Parte de esta configuración es común y otra es específica por tipo de nodo, aunque no es extraño mantener una única configuración por consistencia entre todos los nodos del clúster (esto es que aunque una propiedad no sea tenida en cuenta en un nodo, igualmente esté&mldr; no tengo claro que me guste del todo esto):</p><ul><li><code>jvm.config</code></li><li><code>config.properties</code></li><li><code>node.properties</code></li><li><code>catalog/</code><ul><li><code>A_CATALOG.properties</code></li><li><code>OTHER_CATALOG.properties</code></li><li>etc</li></ul></li></ul><p>Los ficheros dentro de <code>catalog/</code> son los orígenes de datos a los que tendrá acceso Trino. Por ejemplo, para acceder a la cuenta de almacenamiento de Azure crearemos un fichero <code>adls.properties</code> siguiendo la <a href=https://trino.io/docs/current/connector/hive-azure.html#adls-gen2-abfs-storage>documentación</a> del conector:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>connector.name=hive-hadoop2
</span></span><span class=line><span class=cl>hive.metastore.uri=thrift://YOUR_PRIVATE_IP_WHERE_HIVE_IS_RUNNING:9083
</span></span><span class=line><span class=cl>hive.azure.abfs.oauth.endpoint=YOUR_OAUTH_20_TOKEN_ENDPOINT_V1
</span></span><span class=line><span class=cl>hive.azure.abfs.oauth.client-id=YOUR_CLIENT_ID
</span></span><span class=line><span class=cl>hive.azure.abfs.oauth.secret=YOUR_SECRET
</span></span><span class=line><span class=cl>hive.allow-drop-table=true
</span></span></code></pre></div><p>Si el origen fuera <a href=https://trino.io/docs/current/connector/sqlserver.html#configuration>SQL Server</a>, el fichero <code>&lt;YOUR_CATALOG>.properties</code> sería algo así:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>connector.name=sqlserver
</span></span><span class=line><span class=cl>connection-url=jdbc:sqlserver://YOUR_SERVER:1433;database=YOUR_DATABASE
</span></span><span class=line><span class=cl>connection-user=YOUR_USER
</span></span><span class=line><span class=cl>connection-password=YOUR_PASSWORD
</span></span></code></pre></div><blockquote><p>Si quieres que Trino cante, la gallina por delante.</p><p><a href=https://twitter.com/alexmiravet>Alejandro García Miravet</a></p></blockquote><p>Respecto a la memoria asignada a Trino, la <a href="https://trino.io/docs/current/admin/properties-memory-management.html?highlight=memory#">documentación</a> sugiere unos valores predeterminados, pero lógicamente puedes ajustarlos según tu tipo de workload (concurrencia, rendimiento, etc.). <a href=https://aws.amazon.com/es/blogs/big-data/top-9-performance-tuning-tips-for-prestodb-on-amazon-emr/>En este otro enlace</a> apuestan por subir ligeramente la memoria asignada. A modo de resumen, la configuración más relevante en relación al uso de la memoria podría ser esta (aunque como podrás imaginar hay otras muchas propiedades).</p><table><thead><tr><th>Fichero</th><th>Propiedad</th><th>Descripción</th></tr></thead><tbody><tr><td>jvm.config</td><td><code>-Xmx##G</code></td><td>80% de la memoria del nodo.</td></tr><tr><td>config.properties</td><td><code>query.max-memory</code></td><td>La cantidad máxima de memoria que puede usar una consulta en todo el clúster.Número de nodos worker * <code>query.max-total-memory-per-node</code></td></tr><tr><td>config.properties</td><td><code>query.max-memory-per-node</code></td><td>La cantidad máxima de memoria que puede usar una consulta en un nodo.<code>-Xmx##G</code> * 0.2</td></tr><tr><td>config.properties</td><td><code>query.max-total-memory-per-node</code></td><td>La cantidad máxima de memoria de usuario y de sistema (que no controla Trino) que puede usar una consulta en un nodo.<code>-Xmx##G</code> * 0.3</td></tr></tbody></table><p>Si no has cambiado el tamaño de los nodos en el fichero <code>cluster.sh</code>, quizás quieras subirlos de tamaño (a mí me ha pasado varias veces), con este script podemos hacerlo de forma conjunta:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=nv>size</span><span class=o>=</span>NEW_SIZE
</span></span><span class=line><span class=cl>az vm resize --resource-group rg-trino --name vm-coordinator --size <span class=nv>$size</span>
</span></span><span class=line><span class=cl><span class=k>for</span> worker in <span class=o>{</span>1..2<span class=o>}</span>
</span></span><span class=line><span class=cl><span class=k>do</span>
</span></span><span class=line><span class=cl>   az vm resize --resource-group rg-trino --name vm-worker<span class=nv>$worker</span> --size <span class=nv>$size</span>
</span></span><span class=line><span class=cl><span class=k>done</span>
</span></span></code></pre></div><p>Teniendo un clúster de 3 nodos del tamaño <em>Standard_DS3_v2</em> (14GB).</p><p><code>jvm.config</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>-server
</span></span><span class=line><span class=cl>-Xmx11G
</span></span><span class=line><span class=cl>-XX:+UseG1GC
</span></span><span class=line><span class=cl>-XX:G1HeapRegionSize=32M
</span></span><span class=line><span class=cl>-XX:+UseGCOverheadLimit
</span></span><span class=line><span class=cl>-XX:+ExplicitGCInvokesConcurrent
</span></span><span class=line><span class=cl>-XX:+HeapDumpOnOutOfMemoryError
</span></span><span class=line><span class=cl>-XX:+ExitOnOutOfMemoryError
</span></span><span class=line><span class=cl>-Djdk.attach.allowAttachSelf=true
</span></span></code></pre></div><p><code>config.properties</code> (coordinator)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>coordinator=true
</span></span><span class=line><span class=cl>node-scheduler.include-coordinator=false
</span></span><span class=line><span class=cl>http-server.http.port=8080
</span></span><span class=line><span class=cl>query.max-memory=4GB
</span></span><span class=line><span class=cl>query.max-memory-per-node=2GB
</span></span><span class=line><span class=cl>query.max-total-memory-per-node=3GB
</span></span><span class=line><span class=cl>discovery-server.enabled=true
</span></span><span class=line><span class=cl>discovery.uri=http://localhost:8080
</span></span><span class=line><span class=cl>spill-enabled=true
</span></span><span class=line><span class=cl>spiller-spill-path=/home/azureuser/spilling
</span></span></code></pre></div><p><code>config.properties</code> (worker)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>coordinator=false
</span></span><span class=line><span class=cl>http-server.http.port=8080
</span></span><span class=line><span class=cl>query.max-memory=4GB
</span></span><span class=line><span class=cl>query.max-memory-per-node=2GB
</span></span><span class=line><span class=cl>query.max-total-memory-per-node=3GB
</span></span><span class=line><span class=cl>discovery.uri=http://YOUR_PRIVATE_COORDINATOR_IP:8080
</span></span><span class=line><span class=cl>spill-enabled=true
</span></span><span class=line><span class=cl>spiller-spill-path=/home/azureuser/spilling
</span></span></code></pre></div><p>Antes de copiar la configuración, instalaremos Trino en el clúster con <code>install_trino.sh</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=nv>password</span><span class=o>=</span>YOUR_PASSWORD
</span></span><span class=line><span class=cl><span class=nv>coordinator_public_ip</span><span class=o>=</span>YOUR_PUBLIC_COORDINATOR_IP
</span></span><span class=line><span class=cl>sshpass -p <span class=nv>$password</span> scp -r -o <span class=nv>StrictHostKeyChecking</span><span class=o>=</span>no install_trino_coordinator.sh azureuser@<span class=nv>$coordinator_public_ip</span>:/home/azureuser/
</span></span><span class=line><span class=cl>sshpass -p <span class=nv>$password</span> ssh -o <span class=nv>StrictHostKeyChecking</span><span class=o>=</span>no azureuser@<span class=nv>$coordinator_public_ip</span> <span class=s1>&#39;chmod +x install_trino_coordinator.sh;./install_trino_coordinator.sh&#39;</span>
</span></span><span class=line><span class=cl><span class=nv>workers_public_ips</span><span class=o>=(</span>YOUR_PUBLIC_WORKER_1_IP, YOUR_PUBLIC_WORKER_2_IP<span class=o>)</span> 
</span></span><span class=line><span class=cl><span class=k>for</span> worker_public_ip in <span class=s2>&#34;</span><span class=si>${</span><span class=nv>workers_public_ips</span><span class=p>[@]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl><span class=k>do</span> 
</span></span><span class=line><span class=cl>    sshpass -p <span class=nv>$password</span> scp -r -o <span class=nv>StrictHostKeyChecking</span><span class=o>=</span>no install_trino_worker.sh azureuser@<span class=nv>$worker_public_ip</span>:/home/azureuser/
</span></span><span class=line><span class=cl>    sshpass -p <span class=nv>$password</span> ssh -o <span class=nv>StrictHostKeyChecking</span><span class=o>=</span>no azureuser@<span class=nv>$worker_public_ip</span> <span class=s1>&#39;chmod +x install_trino_worker.sh;./install_trino_worker.sh&#39;</span>
</span></span><span class=line><span class=cl><span class=k>done</span>
</span></span></code></pre></div><p><code>install_coordinator.sh</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span>wget -q https://repo1.maven.org/maven2/io/trino/trino-server/360/trino-server-360.tar.gz -O trino-server-360.tar.gz
</span></span><span class=line><span class=cl>tar -xzvf trino-server-360.tar.gz
</span></span><span class=line><span class=cl>mkdir trino-server-360/etc
</span></span><span class=line><span class=cl>wget -q https://repo1.maven.org/maven2/io/trino/trino-cli/360/trino-cli-360-executable.jar -O trino-cli-360-executable.jar
</span></span><span class=line><span class=cl>mv trino-cli-360-executable.jar trino-server-360/trino
</span></span><span class=line><span class=cl>sudo chmod +x trino-server-360/trino
</span></span><span class=line><span class=cl><span class=nb>echo</span> <span class=s1>&#39;export PATH=$PATH:~/trino-server-360&#39;</span> &gt;&gt; .bashrc
</span></span></code></pre></div><p><code>install_worker.sh</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span>wget -q https://repo1.maven.org/maven2/io/trino/trino-server/360/trino-server-360.tar.gz -O trino-server-360.tar.gz
</span></span><span class=line><span class=cl>tar -xzvf trino-server-360.tar.gz
</span></span><span class=line><span class=cl>mkdir trino-server-360/etc
</span></span></code></pre></div><p>Después de instalar Trino, copiaremos la configuración desde local con <code>configuration.sh</code> (que es cómodo porque podemos cambiarla en local y actualizar todo los nodos del clúster ejecutando este fichero en local):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=nv>password</span><span class=o>=</span>YOUR_PASSWORD
</span></span><span class=line><span class=cl><span class=nv>coordinator_public_ip</span><span class=o>=</span>YOUR_PUBLIC_COORDINATOR_IP 
</span></span><span class=line><span class=cl>sshpass -p <span class=nv>$password</span> scp -r -o <span class=nv>StrictHostKeyChecking</span><span class=o>=</span>no vm-coordinator/* azureuser@<span class=nv>$coordinator_public_ip</span>:/home/azureuser/trino-server-360/etc/
</span></span><span class=line><span class=cl><span class=nv>workers_public_ips</span><span class=o>=(</span>YOUR_PUBLIC_WORKER_1_IP, YOUR_PUBLIC_WORKER_2_IP<span class=o>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> worker_public_ip in <span class=s2>&#34;</span><span class=si>${</span><span class=nv>workers_public_ips</span><span class=p>[@]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl><span class=k>do</span> 
</span></span><span class=line><span class=cl>    sshpass -p <span class=nv>$password</span> scp -r -o <span class=nv>StrictHostKeyChecking</span><span class=o>=</span>no vm-worker/* azureuser@<span class=nv>$worker_public_ip</span>:/home/azureuser/trino-server-360/etc/
</span></span><span class=line><span class=cl><span class=k>done</span>
</span></span></code></pre></div><p>El fichero de configuración <code>node.properties</code> es distinto por nodo del clúster (<code>node.id</code> es un GUID y tiene que ser siempre el mismo aunque se reinicia el servidor), así que nos va tocar crearlo a mano en cada nodo:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>node.environment=dev/testing
</span></span><span class=line><span class=cl>node.id=071e53fd-0f92-45d2-acd3-973ddf4b504e
</span></span><span class=line><span class=cl>node.data-dir=/home/azureuser/trino-server-360/data
</span></span></code></pre></div><p>Ahora que está todo listo y tenemos que ejecutar Trino en todos los nodos, podemos usar <a href=https://mobaxterm.mobatek.net/>MobaXterm</a> y su característica <a href=https://mobaxterm.mobatek.net/features.html>MultiExec</a> para ejecutar el comando <code>trino-server-360/bin/launcher start</code>:</p><p><img src=images/mobaxterm_multiexec.gif alt="MultiExec en MobaXterm"></p><p>Si todo ha ido bien, en <em>http://YOUR_COORDINATOR_PUBLIC_IP:8080</em> podrás acceder a Trino y ver que el clúster está levantando.</p><p>Para probar que podemos acceder a los ficheros de nuestra cuenta de almacenamiento, ejecuta el cliente <code>trino</code> desde el coordinator y crea una tabla que apunte al directorio adecuado (en el caso de SQL Server todo esto no es necesario, las tablas ya estarán listas):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=n>USE</span><span class=w> </span><span class=n>adls</span><span class=p>.</span><span class=k>default</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=k>IF</span><span class=w> </span><span class=k>NOT</span><span class=w> </span><span class=k>EXISTS</span><span class=w> </span><span class=n>daily_stock</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>PointOfSaleId</span><span class=w> </span><span class=nb>INTEGER</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>ProductId</span><span class=w> </span><span class=nb>INTEGER</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nb>Date</span><span class=w> </span><span class=nb>DATE</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>Quantity</span><span class=w> </span><span class=nb>INTEGER</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>WITH</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>external_location</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;abfss://YOUR_CONTAINER@YOUR_STORAGE_ACCOUNT.dfs.core.windows.net/daily_stock&#39;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>format</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;PARQUET&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>SELECT</span><span class=w> </span><span class=nb>Date</span><span class=p>,</span><span class=w> </span><span class=k>SUM</span><span class=p>(</span><span class=n>Quantity</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>Quantity</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>daily_stock</span><span class=w> </span><span class=k>GROUP</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=nb>Date</span><span class=w> </span><span class=k>LIMIT</span><span class=w> </span><span class=mi>5</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p><img src=images/trino_sql.png alt="trino en ejecución"></p><p>Como último apunte, ahora mismo en Trino ni el servidor es seguro (http) ni hay <a href=https://trino.io/docs/current/security/overview.html#authentication>seguridad</a> de usuarios. Usar un <a href=https://trino.io/docs/current/security/password-file.html>fichero de usuarios/contraseñas</a> en el servidor no parece lo mejor opción, pero podría ser suficiente en un entorno de dev/testing. Con <code>htpasswd -c -B -C 10 trino-server-360/etc/password.db azureuser</code> podemos generar el fichero de usuarios/contraseñas y en cuanto a https, podemos generar un certificado auto-firmado con las siguientes instrucciones:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days <span class=m>365</span> -nodes
</span></span><span class=line><span class=cl>cat key.pem cert.pem &gt; clustercoord.pem
</span></span></code></pre></div><p>Para hacer efectiva la seguridad, hay que modificar el fichero <code>config.properties</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>http-server.authentication.type=PASSWORD
</span></span><span class=line><span class=cl>http-server.https.enabled=true
</span></span><span class=line><span class=cl>http-server.https.port=8443
</span></span><span class=line><span class=cl>http-server.https.keystore.path=/home/azureuser/trino-server-360/clustercoord.pem
</span></span></code></pre></div><p>Y añadir el fichero <code>password-authenticator.properties</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>password-authenticator.name=file
</span></span><span class=line><span class=cl>file.password-file=/home/azureuser/trino-server-360/etc/password.db
</span></span></code></pre></div><p>Un saludo!</p><div class=blog-tags><a href=https://panicoenlaxbox.com/tags/azure/>azure</a>&nbsp;
<a href=https://panicoenlaxbox.com/tags/trino/>trino</a>&nbsp;</div><hr><section id=social-share><div class="list-inline footer-links"><div class=share-box aria-hidden=true><ul class=share><li><a href="//twitter.com/share?url=https%3a%2f%2fpanicoenlaxbox.com%2fpost%2ftrino-en-azure%2f&text=Trino%20en%20Azure&via=panicoenlaxbox" target=_blank title="Share on Twitter"><i class="fab fa-twitter"></i></a></li><li><a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fpanicoenlaxbox.com%2fpost%2ftrino-en-azure%2f&title=Trino%20en%20Azure" target=_blank title="Share on LinkedIn"><i class="fab fa-linkedin"></i></a></li></ul></div></div></section><h4 class=see-also>Ver también</h4><ul><li><a href=/post/hugo-azure-static-web-app/>Hugo en una Azure Static Web App</a></li><li><a href=/post/powershell-azure-resources/>Script de PowerShell para listar recursos de Azure</a></li></ul></article><ul class="pager blog-pager"><li class=previous><a href=https://panicoenlaxbox.com/post/hugo-azure-static-web-app/ data-toggle=tooltip data-placement=top title="Hugo en una Azure Static Web App">&larr; Artículo anterior</a></li><li class=next><a href=https://panicoenlaxbox.com/post/primeros-pasos-python/ data-toggle=tooltip data-placement=top title="Primeros pasos con Python">Artículo siguiente &rarr;</a></li></ul><div class=disqus-comments><button id=show-comments class="btn btn-default" type=button>Mostrar <span class=disqus-comment-count data-disqus-url=https://panicoenlaxbox.com/post/trino-en-azure>comentarios</span></button><div id=disqus_thread></div><script type=text/javascript>var disqus_config=function(){this.page.url="https://panicoenlaxbox.com/post/trino-en-azure"}</script></div></div></div></div><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href=mailto:panicoenlaxbox@gmail.com title="Email me"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://github.com/panicoenlaxbox title=GitHub><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://twitter.com/panicoenlaxbox title=Twitter><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-twitter fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://linkedin.com/in/sergio-le%c3%b3n-gonz%c3%a1lez-49412642 title=LinkedIn><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-linkedin fa-stack-1x fa-inverse"></i></span></a></li><li><a href title=RSS><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="credits copyright text-muted">Sergio León
&nbsp;&bull;&nbsp;&copy;
2022
&nbsp;&bull;&nbsp;
<a href=https://panicoenlaxbox.com>Programación desordenada</a></p><p class="credits theme-by text-muted"><a href=https://gohugo.io>Hugo v0.107.0</a> alimentada &nbsp;&bull;&nbsp; Tema <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a> adaptado de <a href=https://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a></p></div></div></div></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js integrity=sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js integrity=sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe crossorigin=anonymous></script>
<script src=https://code.jquery.com/jquery-1.12.4.min.js integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin=anonymous></script>
<script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script>
<script src=https://panicoenlaxbox.com/js/main.js></script>
<script src=https://panicoenlaxbox.com/js/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script>$(document).ready(function(){$("pre.chroma").css("padding","0")})</script><script>renderMathInElement(document.body)</script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js integrity=sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js integrity=sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q crossorigin=anonymous></script><script src=https://panicoenlaxbox.com/js/load-photoswipe.js></script>
<script type=text/javascript>$(function(){$("#show-comments").on("click",function(){var e="panicoenlaxbox-github-io";(function(){var t=document.createElement("script");t.type="text/javascript",t.async=!0,t.src="//"+e+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(t)})(),$(this).hide()})})</script><script id=dsq-count-scr src=//panicoenlaxbox-github-io.disqus.com/count.js async></script></body></html>